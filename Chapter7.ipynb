{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ensembles\"\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.904\n",
      "SVC 0.896\n",
      "VotingClassifier 0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8986666666666666"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41899441, 0.58100559],\n",
       "       [0.35502959, 0.64497041],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07909605, 0.92090395],\n",
       "       [0.36144578, 0.63855422],\n",
       "       [0.01578947, 0.98421053],\n",
       "       [0.98285714, 0.01714286],\n",
       "       [0.97927461, 0.02072539],\n",
       "       [0.78165939, 0.21834061],\n",
       "       [0.00578035, 0.99421965],\n",
       "       [0.71052632, 0.28947368],\n",
       "       [0.7967033 , 0.2032967 ],\n",
       "       [0.96111111, 0.03888889],\n",
       "       [0.05789474, 0.94210526],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98461538, 0.01538462],\n",
       "       [0.93548387, 0.06451613],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00591716, 0.99408284],\n",
       "       [0.36206897, 0.63793103],\n",
       "       [0.92670157, 0.07329843],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99465241, 0.00534759],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64878049, 0.35121951],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00531915, 0.99468085],\n",
       "       [0.        , 1.        ],\n",
       "       [0.15      , 0.85      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00552486, 0.99447514],\n",
       "       [0.35294118, 0.64705882],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.26347305, 0.73652695],\n",
       "       [0.3442623 , 0.6557377 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02197802, 0.97802198],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00540541, 0.99459459],\n",
       "       [0.98913043, 0.01086957],\n",
       "       [0.8742515 , 0.1257485 ],\n",
       "       [0.9673913 , 0.0326087 ],\n",
       "       [0.97701149, 0.02298851],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06896552, 0.93103448],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00588235, 0.99411765],\n",
       "       [1.        , 0.        ],\n",
       "       [0.86315789, 0.13684211],\n",
       "       [0.33009709, 0.66990291],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.65030675, 0.34969325],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.83522727, 0.16477273],\n",
       "       [1.        , 0.        ],\n",
       "       [0.65384615, 0.34615385],\n",
       "       [0.14450867, 0.85549133],\n",
       "       [0.62430939, 0.37569061],\n",
       "       [0.9244186 , 0.0755814 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.22279793, 0.77720207],\n",
       "       [0.87830688, 0.12169312],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00549451, 0.99450549],\n",
       "       [0.06153846, 0.93846154],\n",
       "       [0.03365385, 0.96634615],\n",
       "       [0.2826087 , 0.7173913 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.87564767, 0.12435233],\n",
       "       [0.00568182, 0.99431818],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.27272727, 0.72727273],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93604651, 0.06395349],\n",
       "       [0.77647059, 0.22352941],\n",
       "       [0.00595238, 0.99404762],\n",
       "       [1.        , 0.        ],\n",
       "       [0.1978022 , 0.8021978 ],\n",
       "       [0.6281407 , 0.3718593 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03314917, 0.96685083],\n",
       "       [0.4852071 , 0.5147929 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02793296, 0.97206704],\n",
       "       [1.        , 0.        ],\n",
       "       [0.29268293, 0.70731707],\n",
       "       [0.52808989, 0.47191011],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00581395, 0.99418605],\n",
       "       [0.98895028, 0.01104972],\n",
       "       [0.28      , 0.72      ],\n",
       "       [0.89189189, 0.10810811],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.79787234, 0.20212766],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02083333, 0.97916667],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98445596, 0.01554404],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95555556, 0.04444444],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02298851, 0.97701149],\n",
       "       [0.21761658, 0.78238342],\n",
       "       [0.94021739, 0.05978261],\n",
       "       [0.31764706, 0.68235294],\n",
       "       [0.98974359, 0.01025641],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.6978022 , 0.3021978 ],\n",
       "       [0.35204082, 0.64795918],\n",
       "       [0.3625731 , 0.6374269 ],\n",
       "       [0.89119171, 0.10880829],\n",
       "       [0.95238095, 0.04761905],\n",
       "       [0.07514451, 0.92485549],\n",
       "       [0.7688172 , 0.2311828 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01162791, 0.98837209],\n",
       "       [0.98947368, 0.01052632],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01036269, 0.98963731],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.92432432, 0.07567568],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.3877551 , 0.6122449 ],\n",
       "       [0.26666667, 0.73333333],\n",
       "       [0.00574713, 0.99425287],\n",
       "       [0.00531915, 0.99468085],\n",
       "       [0.28795812, 0.71204188],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99462366, 0.00537634],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00512821, 0.99487179],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98984772, 0.01015228],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00460829, 0.99539171],\n",
       "       [0.67039106, 0.32960894],\n",
       "       [0.90697674, 0.09302326],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98857143, 0.01142857],\n",
       "       [0.99428571, 0.00571429],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.09625668, 0.90374332],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03389831, 0.96610169],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02512563, 0.97487437],\n",
       "       [0.9950495 , 0.0049505 ],\n",
       "       [0.93532338, 0.06467662],\n",
       "       [0.7032967 , 0.2967033 ],\n",
       "       [0.59649123, 0.40350877],\n",
       "       [0.        , 1.        ],\n",
       "       [0.125     , 0.875     ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95698925, 0.04301075],\n",
       "       [0.98795181, 0.01204819],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00546448, 0.99453552],\n",
       "       [0.        , 1.        ],\n",
       "       [0.42929293, 0.57070707],\n",
       "       [0.83798883, 0.16201117],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01117318, 0.98882682],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98387097, 0.01612903],\n",
       "       [0.        , 1.        ],\n",
       "       [0.24861878, 0.75138122],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97560976, 0.02439024],\n",
       "       [0.82608696, 0.17391304],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08695652, 0.91304348],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02617801, 0.97382199],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06626506, 0.93373494],\n",
       "       [1.        , 0.        ],\n",
       "       [0.76884422, 0.23115578],\n",
       "       [0.        , 1.        ],\n",
       "       [0.87634409, 0.12365591],\n",
       "       [0.98536585, 0.01463415],\n",
       "       [0.16580311, 0.83419689],\n",
       "       [0.225     , 0.775     ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.20359281, 0.79640719],\n",
       "       [0.94054054, 0.05945946],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.50549451, 0.49450549],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.09139785, 0.90860215],\n",
       "       [0.06703911, 0.93296089],\n",
       "       [0.98181818, 0.01818182],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.38095238, 0.61904762],\n",
       "       [0.09090909, 0.90909091],\n",
       "       [0.4742268 , 0.5257732 ],\n",
       "       [0.53763441, 0.46236559],\n",
       "       [0.01149425, 0.98850575],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.58201058, 0.41798942],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.23214286, 0.76785714],\n",
       "       [0.79896907, 0.20103093],\n",
       "       [0.06936416, 0.93063584],\n",
       "       [1.        , 0.        ],\n",
       "       [0.84269663, 0.15730337],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00552486, 0.99447514],\n",
       "       [0.12777778, 0.87222222],\n",
       "       [0.01415094, 0.98584906],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.91071429, 0.08928571],\n",
       "       [0.13812155, 0.86187845],\n",
       "       [0.94708995, 0.05291005],\n",
       "       [0.01136364, 0.98863636],\n",
       "       [0.5862069 , 0.4137931 ],\n",
       "       [0.09497207, 0.90502793],\n",
       "       [0.98830409, 0.01169591],\n",
       "       [0.81818182, 0.18181818],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94350282, 0.05649718],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.27840909, 0.72159091],\n",
       "       [0.99479167, 0.00520833],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00540541, 0.99459459],\n",
       "       [0.84895833, 0.15104167],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.76923077, 0.23076923],\n",
       "       [0.9144385 , 0.0855615 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.69430052, 0.30569948],\n",
       "       [0.49717514, 0.50282486],\n",
       "       [0.00540541, 0.99459459],\n",
       "       [0.9       , 0.1       ],\n",
       "       [0.00546448, 0.99453552],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85964912, 0.14035088],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.74157303, 0.25842697],\n",
       "       [0.12432432, 0.87567568],\n",
       "       [0.44578313, 0.55421687],\n",
       "       [0.234375  , 0.765625  ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9015544 , 0.0984456 ],\n",
       "       [0.80666667, 0.19333333],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02072539, 0.97927461],\n",
       "       [0.94923858, 0.05076142],\n",
       "       [0.96774194, 0.03225806],\n",
       "       [1.        , 0.        ],\n",
       "       [0.51648352, 0.48351648],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97883598, 0.02116402],\n",
       "       [0.00564972, 0.99435028],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93922652, 0.06077348],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04022989, 0.95977011],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01162791, 0.98837209],\n",
       "       [1.        , 0.        ],\n",
       "       [0.10928962, 0.89071038],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01025641, 0.98974359],\n",
       "       [0.        , 1.        ],\n",
       "       [0.38857143, 0.61142857],\n",
       "       [0.0591133 , 0.9408867 ],\n",
       "       [0.25423729, 0.74576271],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.18421053, 0.81578947],\n",
       "       [0.98895028, 0.01104972],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95731707, 0.04268293],\n",
       "       [0.26486486, 0.73513514],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00990099, 0.99009901],\n",
       "       [0.98857143, 0.01142857],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03389831, 0.96610169],\n",
       "       [0.98941799, 0.01058201],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02515723, 0.97484277],\n",
       "       [0.6       , 0.4       ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_features=\"auto\", max_leaf_nodes=16),\n",
    "    n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.10035667189208082\n",
      "sepal width (cm) 0.022627277927040675\n",
      "petal length (cm) 0.45849400484788505\n",
      "petal width (cm) 0.4185220453329934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75026781])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=2, n_estimators=85)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred)\n",
    "          for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators = np.argmin(errors) + 1\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2,n_estimators=bst_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break  # early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "xgb_reg = xgboost.XGBRegressor()\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "y_pred = xgb_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.22055\n",
      "Will train until validation_0-rmse hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-rmse:0.16547\n",
      "[2]\tvalidation_0-rmse:0.12243\n",
      "[3]\tvalidation_0-rmse:0.10044\n",
      "[4]\tvalidation_0-rmse:0.08467\n",
      "[5]\tvalidation_0-rmse:0.07344\n",
      "[6]\tvalidation_0-rmse:0.06728\n",
      "[7]\tvalidation_0-rmse:0.06383\n",
      "[8]\tvalidation_0-rmse:0.06125\n",
      "[9]\tvalidation_0-rmse:0.05959\n",
      "[10]\tvalidation_0-rmse:0.05902\n",
      "[11]\tvalidation_0-rmse:0.05852\n",
      "[12]\tvalidation_0-rmse:0.05844\n",
      "[13]\tvalidation_0-rmse:0.05801\n",
      "[14]\tvalidation_0-rmse:0.05747\n",
      "[15]\tvalidation_0-rmse:0.05772\n",
      "[16]\tvalidation_0-rmse:0.05778\n",
      "Stopping. Best iteration:\n",
      "[14]\tvalidation_0-rmse:0.05747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_reg.fit(X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
    "y_pred = xgb_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
